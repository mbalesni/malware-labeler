import json
import numpy as np
import h5py
import pandas as pd
import os
import math
import matplotlib.pyplot as plt
from PIL import Image
import random

DETECTION_THRESHOLD = 0.5
FIXED_WIDTH = 384
FINAL_SIZE = 384
SEED = 1

CLASSES = ['benign', 'malicious']

def list_files(dir_name, extension = None):
    paths = []
    for root, _, files in os.walk(dir_name):
        for f in files:
            if (extension is not None and extension is not False and extension in f) or (extension is None):
                paths.append(os.path.join(root, f))
            elif extension is False:
                if not '.' in f:
                    paths.append(os.path.join(root, f))
    return paths

def unison_shuffle(X, y, use_seed):
    assert len(X) == len(y)
    if use_seed == True:
        np.random.seed(SEED)
    p = np.random.permutation(len(X))
    return X[p], y[p]

def filter_file_by_height(filepath, width, min_height = 200, max_height = 500):
    size = os.path.getsize(filepath)
    height = math.ceil(size / FIXED_WIDTH)

    if height >= min_height and height <= max_height:
        return True
    else:
        return False


def create_and_save_image(path_to_input, output_folder):
    # load file
    img = np.fromfile(path_to_input, dtype='uint8')

    # resize to (None, FIXED_WIDTH)
    num_pixels = img.shape[0]
    columns = FIXED_WIDTH
    rows = math.ceil(num_pixels / 384)
    total_size = columns * rows
    img.resize(total_size)
    img = img.reshape((rows, columns))
    
    # convert to RGB using a cmap
    cmap = plt.get_cmap('viridis')
    rgba_img = cmap(img)
    img = np.delete(rgba_img, 3, 2)    
    
    # resize to (FINAL_SIZE, FINAL_SIZE)
    img = np.uint8(img * 255)
    pic = Image.fromarray(img)
    pic = pic.resize((FINAL_SIZE, FINAL_SIZE), Image.ANTIALIAS)

    # save image as a file
    original_file_name = path_to_input.split('/')[-1]
    save_path = os.path.join(output_folder, original_file_name)
    pic.save(save_path + '.jpg')

def create_detection_dataset(labels_input_folder = None, examples_input_folder = None, 
                             output_folder = None, train_data = 0.8, use_seed = True):

    # create a dict of <hash>:<detected> pairs
    hashes_detection = {}
    result_files = list_files(labels_input_folder, extension='.json')
    print('Found ' + str(len(result_files))+ ' result files. Using them to create a dataset...')
    for f in result_files:
        with open (f, 'r') as result_file:
            sample_hash = f.split('/')[-1].split('.')[0]
            result = json.loads(result_file.read())
            hashes_detection[sample_hash] = (result['detection_percentage'] > DETECTION_THRESHOLD)

    # get a list of filtered hashes
    hashes_list = [hsh for hsh in list(hashes_detection.keys()) if filter_file_by_height(os.path.join(examples_input_folder, hsh), FIXED_WIDTH)]
    m = len(hashes_list)
    print(str(m) + ' examples left after size filtering...')

    # shuffle examples list
    random.Random(SEED).shuffle(hashes_list)

    # train/dev split
    train_samples = int(0.8 * m)

    # save examples as images in a directory hierarchy taken from
    # https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/
    #
    # examples_output_folder
    # ├── train
    # │   ├── benign
    # │   │   └── <some_hash>.jpg
    # │   └── malicious
    # │       └── <some_hash>.jpg
    # └── dev
    #     ├── benign
    #     │   └── <some_hash>.jpg
    #     └── malicious
    #         └── <some_hash>.jpg
    #
    for i, hsh in enumerate(hashes_list):
        path_to_malware_sample = os.path.join(examples_input_folder, hsh)
        label = hashes_detection[hsh] # 0 or 1
        label_verbose = CLASSES[label]

        if i < train_samples:
            output_path = os.path.join(output_folder, 'train', label_verbose)
        else:
            output_path = os.path.join(output_folder, 'dev', label_verbose)

        os.makedirs(output_path, exist_ok=True)
        create_and_save_image(path_to_malware_sample, output_path)

if __name__ == '__main__':
    labels_input_folder = 'labeled-malware'
    examples_input_folder = 'malware.complete'
    output_folder = 'datasets/detection-images'

    create_detection_dataset(labels_input_folder, examples_input_folder, output_folder)

    print('Successfully created dataset at: ', output_folder)

    